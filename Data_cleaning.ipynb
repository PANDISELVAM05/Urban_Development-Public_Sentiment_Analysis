{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6135faac",
   "metadata": {},
   "source": [
    "### Data cleaning1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2de2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "                        Neighborhood_ID                            Request_ID  \\\n",
      "0  1b880b6f-4539-4318-af97-4762f72fa88f  90d28f50-7ea6-4740-a121-4b86f7df2488   \n",
      "1  2b577f21-f383-4363-bab0-4e127e60c207  8ea9e3a9-65fb-4dfb-8b74-010a5c01fa65   \n",
      "2  a87b9c95-9686-4ad1-a8ae-090177006877  17a59af8-3c01-4cba-ad29-f1a73983309c   \n",
      "3  7ab9b23f-9e69-4b03-a857-42a8451ea327  8f8d56db-5e03-4ec5-af50-d109dd00f897   \n",
      "4  c6ccf8c9-cb1e-4e25-b212-04bc043d4562  2fe5e904-3bf7-41b5-889b-8343b1827a4f   \n",
      "\n",
      "           DateTime                      Complaints         Category  \\\n",
      "0  16-10-2024 21:29        Metro late arrival issue  Transport Delay   \n",
      "1  27-02-2025 02:34       Noise pollution complaint  Noise Complaint   \n",
      "2  10-05-2025 19:52          Encroachment complaint     Encroachment   \n",
      "3  24-09-2024 06:18  Garbage not cleared for 3 days          Garbage   \n",
      "4  11-12-2024 00:46  Garbage not cleared for 3 days          Garbage   \n",
      "\n",
      "         Location          Stop_Name   Latitude  Longitude  Status  \\\n",
      "0         Madurai  Virudhunagar Stop  10.030008  76.922709    Open   \n",
      "1  Tiruvannamalai         Salem Town   8.388581  78.487154  Closed   \n",
      "2     Thoothukudi          Nagercoil  12.728683  79.423416    Open   \n",
      "3     Thoothukudi  Nagapattinam Stop  11.625752  78.113328  Closed   \n",
      "4     Krishnagiri         Salem Town   9.183013  77.342635  Closed   \n",
      "\n",
      "   Resolution_Time(hrs)  SumOfComplaints  SumOfCategory  SumOfLocation  \\\n",
      "0                   104                1              1              1   \n",
      "1                   163                2              2              2   \n",
      "2                    50                3              3              3   \n",
      "3                     2                4              4              4   \n",
      "4                    74                5              5              5   \n",
      "\n",
      "   SumOfStatus  \n",
      "0            1  \n",
      "1            2  \n",
      "2            3  \n",
      "3            4  \n",
      "4            5  \n",
      "                           Neighborhood_ID  \\\n",
      "9995  7855e9f6-083d-43b0-9567-857c8a5852fd   \n",
      "9996  79ddee90-3f20-4bc0-aa6e-5736455cbf1a   \n",
      "9997  5c01e1e6-0785-4a41-b13b-35337450d713   \n",
      "9998  137e7042-98b2-4e3e-87c9-7f8fab0ed57f   \n",
      "9999  80f658a0-7474-4055-b02b-6ffc02eb5474   \n",
      "\n",
      "                                Request_ID          DateTime  \\\n",
      "9995  8d6b586d-aa42-49fc-ad54-935b47085504  08-09-2025 12:16   \n",
      "9996  c714f271-f333-452e-8ba8-c0a2c8cf6b02  08-06-2025 16:00   \n",
      "9997  28b81532-e390-4e18-89d6-b593b02219f3  09-02-2025 07:39   \n",
      "9998  c2b8ff30-adaf-4489-954e-5e25febf33e7  18-04-2025 04:55   \n",
      "9999  27d4572e-99b7-4953-951e-c30220d67de1  10-12-2024 19:07   \n",
      "\n",
      "                          Complaints                Category         Location  \\\n",
      "9995           No water supply issue      Water Supply Issue         Namakkal   \n",
      "9996        Blocked stormwater drain           Blocked Drain         Namakkal   \n",
      "9997    Unauthorized billboard issue  Unauthorized Billboard  Tiruchirappalli   \n",
      "9998       Illegal parking complaint         Illegal Parking      Tirunelveli   \n",
      "9999  Garbage not cleared for 3 days                 Garbage        Cuddalore   \n",
      "\n",
      "                Stop_Name   Latitude  Longitude  Status  Resolution_Time(hrs)  \\\n",
      "9995  Coimbatore Junction   8.370297  79.493572  Closed                   198   \n",
      "9996     Kanchipuram Stop   8.042746  80.292005  Closed                    15   \n",
      "9997            Nagercoil   9.521806  76.734564    Open                   100   \n",
      "9998      Dharmapuri Stop  12.470242  78.252973  Closed                   113   \n",
      "9999               Egmore  10.651757  79.748383    Open                    24   \n",
      "\n",
      "      SumOfComplaints  SumOfCategory  SumOfLocation  SumOfStatus  \n",
      "9995              523            481            398         5057  \n",
      "9996              524            482            399         5058  \n",
      "9997              525            483            400         5059  \n",
      "9998              526            484            401         5060  \n",
      "9999              527            485            402         5061  \n",
      "\n",
      "\n",
      "\n",
      "dataset columns:\n",
      "Index(['Neighborhood_ID', 'Request_ID', 'DateTime', 'Complaints', 'Category',\n",
      "       'Location', 'Stop_Name', 'Latitude', 'Longitude', 'Status',\n",
      "       'Resolution_Time(hrs)', 'SumOfComplaints', 'SumOfCategory',\n",
      "       'SumOfLocation', 'SumOfStatus'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "Data Types:\n",
      "Neighborhood_ID          object\n",
      "Request_ID               object\n",
      "DateTime                 object\n",
      "Complaints               object\n",
      "Category                 object\n",
      "Location                 object\n",
      "Stop_Name                object\n",
      "Latitude                float64\n",
      "Longitude               float64\n",
      "Status                   object\n",
      "Resolution_Time(hrs)      int64\n",
      "SumOfComplaints           int64\n",
      "SumOfCategory             int64\n",
      "SumOfLocation             int64\n",
      "SumOfStatus               int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Missing Values in Each Column:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Neighborhood_ID       10000 non-null  object \n",
      " 1   Request_ID            10000 non-null  object \n",
      " 2   DateTime              10000 non-null  object \n",
      " 3   Complaints            10000 non-null  object \n",
      " 4   Category              10000 non-null  object \n",
      " 5   Location              10000 non-null  object \n",
      " 6   Stop_Name             10000 non-null  object \n",
      " 7   Latitude              10000 non-null  float64\n",
      " 8   Longitude             10000 non-null  float64\n",
      " 9   Status                10000 non-null  object \n",
      " 10  Resolution_Time(hrs)  10000 non-null  int64  \n",
      " 11  SumOfComplaints       10000 non-null  int64  \n",
      " 12  SumOfCategory         10000 non-null  int64  \n",
      " 13  SumOfLocation         10000 non-null  int64  \n",
      " 14  SumOfStatus           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(8)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "Neighborhood_ID         0\n",
      "Request_ID              0\n",
      "DateTime                0\n",
      "Complaints              0\n",
      "Category                0\n",
      "Location                0\n",
      "Stop_Name               0\n",
      "Latitude                0\n",
      "Longitude               0\n",
      "Status                  0\n",
      "Resolution_Time(hrs)    0\n",
      "SumOfComplaints         0\n",
      "SumOfCategory           0\n",
      "SumOfLocation           0\n",
      "SumOfStatus             0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "After cleaning (removing rows with only special characters or NaN in any column):\n",
      "                        Neighborhood_ID                            Request_ID  \\\n",
      "0  1b880b6f-4539-4318-af97-4762f72fa88f  90d28f50-7ea6-4740-a121-4b86f7df2488   \n",
      "1  2b577f21-f383-4363-bab0-4e127e60c207  8ea9e3a9-65fb-4dfb-8b74-010a5c01fa65   \n",
      "2  a87b9c95-9686-4ad1-a8ae-090177006877  17a59af8-3c01-4cba-ad29-f1a73983309c   \n",
      "3  7ab9b23f-9e69-4b03-a857-42a8451ea327  8f8d56db-5e03-4ec5-af50-d109dd00f897   \n",
      "4  c6ccf8c9-cb1e-4e25-b212-04bc043d4562  2fe5e904-3bf7-41b5-889b-8343b1827a4f   \n",
      "\n",
      "           DateTime                      Complaints         Category  \\\n",
      "0  16-10-2024 21:29        Metro late arrival issue  Transport Delay   \n",
      "1  27-02-2025 02:34       Noise pollution complaint  Noise Complaint   \n",
      "2  10-05-2025 19:52          Encroachment complaint     Encroachment   \n",
      "3  24-09-2024 06:18  Garbage not cleared for 3 days          Garbage   \n",
      "4  11-12-2024 00:46  Garbage not cleared for 3 days          Garbage   \n",
      "\n",
      "         Location          Stop_Name   Latitude  Longitude  Status  \\\n",
      "0         Madurai  Virudhunagar Stop  10.030008  76.922709    Open   \n",
      "1  Tiruvannamalai         Salem Town   8.388581  78.487154  Closed   \n",
      "2     Thoothukudi          Nagercoil  12.728683  79.423416    Open   \n",
      "3     Thoothukudi  Nagapattinam Stop  11.625752  78.113328  Closed   \n",
      "4     Krishnagiri         Salem Town   9.183013  77.342635  Closed   \n",
      "\n",
      "   Resolution_Time(hrs)  SumOfComplaints  SumOfCategory  SumOfLocation  \\\n",
      "0                   104                1              1              1   \n",
      "1                   163                2              2              2   \n",
      "2                    50                3              3              3   \n",
      "3                     2                4              4              4   \n",
      "4                    74                5              5              5   \n",
      "\n",
      "   SumOfStatus  \n",
      "0            1  \n",
      "1            2  \n",
      "2            3  \n",
      "3            4  \n",
      "4            5  \n",
      "\n",
      "\n",
      "\n",
      "Cleaned data saved to 311_service_requests1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pandi selvam\\AppData\\Local\\Temp\\ipykernel_29192\\1353006216.py:57: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n"
     ]
    }
   ],
   "source": [
    "#DATA CLEANING SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Redirect output to both console and file for Part 1\n",
    "class DualOutput:\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\", encoding=\"utf-8\")\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = DualOutput(\"311_service_requests.txt\")\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Display first few rows\n",
    "# ==============================\n",
    "file_path = r\"D:\\PROJECT\\Project1\\dataset\\311_service_requests.csv\"  \n",
    "df = pd.read_csv(file_path) \n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# =======================================\n",
    "# Step 2: Dataset Columns\n",
    "# =======================================\n",
    "print(\"\\n\\n\\ndataset columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# =======================================\n",
    "# Step 3: Data Types\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "# =======================================\n",
    "# Step 4: Identify Missing Values\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nMissing Values in Each Column:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ===================================================================================\n",
    "# Step 5: Data Cleaning - Remove rows with only special characters or NaN in any cell\n",
    "# ===================================================================================\n",
    "def contains_only_special_chars(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    return bool(re.fullmatch(r'[^a-zA-Z0-9]+', str(value)))\n",
    "\n",
    "df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n",
    "\n",
    "print(\"\\n\\n\\nAfter cleaning (removing rows with only special characters or NaN in any column):\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Save cleaned data for Part 2\n",
    "cleaned_file_path = \"311_service_requests1.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n\\n\\nCleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5036667",
   "metadata": {},
   "source": [
    "### Data_cleaning2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ce823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA CLEANING SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Redirect output to both console and file for Part 1\n",
    "class DualOutput:\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\", encoding=\"utf-8\")\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = DualOutput(\"demographics.txt\")\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Display first few rows\n",
    "# ==============================\n",
    "file_path = r\"D:\\PROJECT\\Project1\\dataset\\demographics.csv\"   # Change to your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# =======================================\n",
    "# Step 2: Dataset Columns\n",
    "# =======================================\n",
    "print(\"\\n\\n\\ndataset columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# =======================================\n",
    "# Step 3: Data Types\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "# =======================================\n",
    "# Step 4: Identify Missing Values\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nMissing Values in Each Column:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ===================================================================================\n",
    "# Step 5: Data Cleaning - Remove rows with only special characters or NaN in any cell\n",
    "# ===================================================================================\n",
    "def contains_only_special_chars(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    return bool(re.fullmatch(r'[^a-zA-Z0-9]+', str(value)))\n",
    "\n",
    "df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n",
    "\n",
    "print(\"\\n\\n\\nAfter cleaning (removing rows with only special characters or NaN in any column):\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Save cleaned data for Part 2\n",
    "cleaned_file_path = \"demographics1.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n\\n\\nCleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf9f29",
   "metadata": {},
   "source": [
    "### Data_cleaning3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA CLEANING SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Redirect output to both console and file for Part 1\n",
    "class DualOutput:\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\", encoding=\"utf-8\")\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = DualOutput(\"public_transport_usage.txt\")\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Display first few rows\n",
    "# ==============================\n",
    "file_path = r\"D:\\PROJECT\\Project1\\dataset\\public_transport_usage.csv\"   # Change to your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# =======================================\n",
    "# Step 2: Dataset Columns\n",
    "# =======================================\n",
    "print(\"\\n\\n\\ndataset columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# =======================================\n",
    "# Step 3: Data Types\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "# =======================================\n",
    "# Step 4: Identify Missing Values\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nMissing Values in Each Column:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ===================================================================================\n",
    "# Step 5: Data Cleaning - Remove rows with only special characters or NaN in any cell\n",
    "# ===================================================================================\n",
    "def contains_only_special_chars(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    return bool(re.fullmatch(r'[^a-zA-Z0-9]+', str(value)))\n",
    "\n",
    "df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n",
    "\n",
    "print(\"\\n\\n\\nAfter cleaning (removing rows with only special characters or NaN in any column):\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Save cleaned data for Part 2\n",
    "cleaned_file_path = \"public_transport_usage1.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n\\n\\nCleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef154a29",
   "metadata": {},
   "source": [
    "### Data_cleaning4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc0669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA CLEANING SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Redirect output to both console and file for Part 1\n",
    "class DualOutput:\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\", encoding=\"utf-8\")\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = DualOutput(\"social_media_sentiment.txt\")\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Display first few rows\n",
    "# ==============================\n",
    "file_path = r\"D:\\PROJECT\\Project1\\dataset\\social_media_sentiment.csv\"   # Change to your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# =======================================\n",
    "# Step 2: Dataset Columns\n",
    "# =======================================\n",
    "print(\"\\n\\n\\ndataset columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# =======================================\n",
    "# Step 3: Data Types\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "# =======================================\n",
    "# Step 4: Identify Missing Values\n",
    "# =======================================\n",
    "print(\"\\n\\n\\nMissing Values in Each Column:\")\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ===================================================================================\n",
    "# Step 5: Data Cleaning - Remove rows with only special characters or NaN in any cell\n",
    "# ===================================================================================\n",
    "def contains_only_special_chars(value):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    return bool(re.fullmatch(r'[^a-zA-Z0-9]+', str(value)))\n",
    "\n",
    "df_cleaned = df[~df.applymap(contains_only_special_chars).any(axis=1)]\n",
    "\n",
    "print(\"\\n\\n\\nAfter cleaning (removing rows with only special characters or NaN in any column):\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Save cleaned data for Part 2\n",
    "cleaned_file_path = \"social_media_sentiment1.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n\\n\\nCleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
